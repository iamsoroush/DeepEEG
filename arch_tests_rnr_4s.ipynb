{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "arch_tests_rnr_4s.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iamsoroush/DeepEEG/blob/master/arch_tests_rnr_4s.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_JCUvRGHlz5M",
        "colab_type": "code",
        "outputId": "90a0d8a8-8300-4861-f06d-ada606d722c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        }
      },
      "source": [
        "#@title # Clone the repository and upgrade Keras {display-mode: \"form\"}\n",
        "\n",
        "!git clone https://github.com/iamsoroush/DeepEEG.git\n",
        "!pip install --upgrade keras"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'DeepEEG'...\n",
            "remote: Enumerating objects: 53, done.\u001b[K\n",
            "remote: Counting objects:   1% (1/53)\u001b[K\rremote: Counting objects:   3% (2/53)\u001b[K\rremote: Counting objects:   5% (3/53)\u001b[K\rremote: Counting objects:   7% (4/53)\u001b[K\rremote: Counting objects:   9% (5/53)\u001b[K\rremote: Counting objects:  11% (6/53)\u001b[K\rremote: Counting objects:  13% (7/53)\u001b[K\rremote: Counting objects:  15% (8/53)\u001b[K\rremote: Counting objects:  16% (9/53)\u001b[K\rremote: Counting objects:  18% (10/53)\u001b[K\rremote: Counting objects:  20% (11/53)\u001b[K\rremote: Counting objects:  22% (12/53)\u001b[K\rremote: Counting objects:  24% (13/53)\u001b[K\rremote: Counting objects:  26% (14/53)\u001b[K\rremote: Counting objects:  28% (15/53)\u001b[K\rremote: Counting objects:  30% (16/53)\u001b[K\rremote: Counting objects:  32% (17/53)\u001b[K\rremote: Counting objects:  33% (18/53)\u001b[K\rremote: Counting objects:  35% (19/53)\u001b[K\rremote: Counting objects:  37% (20/53)\u001b[K\rremote: Counting objects:  39% (21/53)\u001b[K\rremote: Counting objects:  41% (22/53)\u001b[K\rremote: Counting objects:  43% (23/53)\u001b[K\rremote: Counting objects:  45% (24/53)\u001b[K\rremote: Counting objects:  47% (25/53)\u001b[K\rremote: Counting objects:  49% (26/53)\u001b[K\rremote: Counting objects:  50% (27/53)\u001b[K\rremote: Counting objects:  52% (28/53)\u001b[K\rremote: Counting objects:  54% (29/53)\u001b[K\rremote: Counting objects:  56% (30/53)\u001b[K\rremote: Counting objects:  58% (31/53)\u001b[K\rremote: Counting objects:  60% (32/53)\u001b[K\rremote: Counting objects:  62% (33/53)\u001b[K\rremote: Counting objects:  64% (34/53)\u001b[K\rremote: Counting objects:  66% (35/53)\u001b[K\rremote: Counting objects:  67% (36/53)\u001b[K\rremote: Counting objects:  69% (37/53)\u001b[K\rremote: Counting objects:  71% (38/53)\u001b[K\rremote: Counting objects:  73% (39/53)\u001b[K\rremote: Counting objects:  75% (40/53)\u001b[K\rremote: Counting objects:  77% (41/53)\u001b[K\rremote: Counting objects:  79% (42/53)\u001b[K\rremote: Counting objects:  81% (43/53)\u001b[K\rremote: Counting objects:  83% (44/53)\u001b[K\rremote: Counting objects:  84% (45/53)\u001b[K\rremote: Counting objects:  86% (46/53)\u001b[K\rremote: Counting objects:  88% (47/53)\u001b[K\rremote: Counting objects:  90% (48/53)\u001b[K\rremote: Counting objects:  92% (49/53)\u001b[K\rremote: Counting objects:  94% (50/53)\u001b[K\rremote: Counting objects:  96% (51/53)\u001b[K\rremote: Counting objects:  98% (52/53)\u001b[K\rremote: Counting objects: 100% (53/53)\u001b[K\rremote: Counting objects: 100% (53/53), done.\u001b[K\n",
            "remote: Compressing objects:   2% (1/41)\u001b[K\rremote: Compressing objects:   4% (2/41)\u001b[K\rremote: Compressing objects:   7% (3/41)\u001b[K\rremote: Compressing objects:   9% (4/41)\u001b[K\rremote: Compressing objects:  12% (5/41)\u001b[K\rremote: Compressing objects:  14% (6/41)\u001b[K\rremote: Compressing objects:  17% (7/41)\u001b[K\rremote: Compressing objects:  19% (8/41)\u001b[K\rremote: Compressing objects:  21% (9/41)\u001b[K\rremote: Compressing objects:  24% (10/41)\u001b[K\rremote: Compressing objects:  26% (11/41)\u001b[K\rremote: Compressing objects:  29% (12/41)\u001b[K\rremote: Compressing objects:  31% (13/41)\u001b[K\rremote: Compressing objects:  34% (14/41)\u001b[K\rremote: Compressing objects:  36% (15/41)\u001b[K\rremote: Compressing objects:  39% (16/41)\u001b[K\rremote: Compressing objects:  41% (17/41)\u001b[K\rremote: Compressing objects:  43% (18/41)\u001b[K\rremote: Compressing objects:  46% (19/41)\u001b[K\rremote: Compressing objects:  48% (20/41)\u001b[K\rremote: Compressing objects:  51% (21/41)\u001b[K\rremote: Compressing objects:  53% (22/41)\u001b[K\rremote: Compressing objects:  56% (23/41)\u001b[K\rremote: Compressing objects:  58% (24/41)\u001b[K\rremote: Compressing objects:  60% (25/41)\u001b[K\rremote: Compressing objects:  63% (26/41)\u001b[K\rremote: Compressing objects:  65% (27/41)\u001b[K\rremote: Compressing objects:  68% (28/41)\u001b[K\rremote: Compressing objects:  70% (29/41)\u001b[K\rremote: Compressing objects:  73% (30/41)\u001b[K\rremote: Compressing objects:  75% (31/41)\u001b[K\rremote: Compressing objects:  78% (32/41)\u001b[K\rremote: Compressing objects:  80% (33/41)\u001b[K\rremote: Compressing objects:  82% (34/41)\u001b[K\rremote: Compressing objects:  85% (35/41)\u001b[K\rremote: Compressing objects:  87% (36/41)\u001b[K\rremote: Compressing objects:  90% (37/41)\u001b[K\rremote: Compressing objects:  92% (38/41)\u001b[K\rremote: Compressing objects:  95% (39/41)\u001b[K\rremote: Compressing objects:  97% (40/41)\u001b[K\rremote: Compressing objects: 100% (41/41)\u001b[K\rremote: Compressing objects: 100% (41/41), done.\u001b[K\n",
            "remote: Total 53 (delta 24), reused 30 (delta 12), pack-reused 0\u001b[K\n",
            "Unpacking objects:   1% (1/53)   \rUnpacking objects:   3% (2/53)   \rUnpacking objects:   5% (3/53)   \rUnpacking objects:   7% (4/53)   \rUnpacking objects:   9% (5/53)   \rUnpacking objects:  11% (6/53)   \rUnpacking objects:  13% (7/53)   \rUnpacking objects:  15% (8/53)   \rUnpacking objects:  16% (9/53)   \rUnpacking objects:  18% (10/53)   \rUnpacking objects:  20% (11/53)   \rUnpacking objects:  22% (12/53)   \rUnpacking objects:  24% (13/53)   \rUnpacking objects:  26% (14/53)   \rUnpacking objects:  28% (15/53)   \rUnpacking objects:  30% (16/53)   \rUnpacking objects:  32% (17/53)   \rUnpacking objects:  33% (18/53)   \rUnpacking objects:  35% (19/53)   \rUnpacking objects:  37% (20/53)   \rUnpacking objects:  39% (21/53)   \rUnpacking objects:  41% (22/53)   \rUnpacking objects:  43% (23/53)   \rUnpacking objects:  45% (24/53)   \rUnpacking objects:  47% (25/53)   \rUnpacking objects:  49% (26/53)   \rUnpacking objects:  50% (27/53)   \rUnpacking objects:  52% (28/53)   \rUnpacking objects:  54% (29/53)   \rUnpacking objects:  56% (30/53)   \rUnpacking objects:  58% (31/53)   \rUnpacking objects:  60% (32/53)   \rUnpacking objects:  62% (33/53)   \rUnpacking objects:  64% (34/53)   \rUnpacking objects:  66% (35/53)   \rUnpacking objects:  67% (36/53)   \rUnpacking objects:  69% (37/53)   \rUnpacking objects:  71% (38/53)   \rUnpacking objects:  73% (39/53)   \rUnpacking objects:  75% (40/53)   \rUnpacking objects:  77% (41/53)   \rUnpacking objects:  79% (42/53)   \rUnpacking objects:  81% (43/53)   \rUnpacking objects:  83% (44/53)   \rUnpacking objects:  84% (45/53)   \rUnpacking objects:  86% (46/53)   \rUnpacking objects:  88% (47/53)   \rUnpacking objects:  90% (48/53)   \rUnpacking objects:  92% (49/53)   \rUnpacking objects:  94% (50/53)   \rUnpacking objects:  96% (51/53)   \rUnpacking objects:  98% (52/53)   \rUnpacking objects: 100% (53/53)   \rUnpacking objects: 100% (53/53), done.\n",
            "Requirement already up-to-date: keras in /usr/local/lib/python3.6/dist-packages (2.3.1)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras) (1.17.3)\n",
            "Requirement already satisfied, skipping upgrade: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras) (1.0.8)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras) (1.12.0)\n",
            "Requirement already satisfied, skipping upgrade: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras) (3.13)\n",
            "Requirement already satisfied, skipping upgrade: h5py in /usr/local/lib/python3.6/dist-packages (from keras) (2.8.0)\n",
            "Requirement already satisfied, skipping upgrade: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras) (1.3.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7_sHB4_nsc8J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm -r DeepEEG"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-dMfhjVypjFa",
        "colab_type": "code",
        "outputId": "2dbcf7ab-0ab8-4dd6-c8c2-cbf76541fb0c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        }
      },
      "source": [
        "#@title # Imports {display-mode: \"form\"}\n",
        "\n",
        "import os\n",
        "import pickle\n",
        "import sys\n",
        "sys.path.append('DeepEEG')\n",
        "\n",
        "PACKAGE_PARENT = '..'\n",
        "SCRIPT_DIR = os.path.dirname(os.path.realpath(os.getcwd()))\n",
        "sys.path.append(os.path.normpath(os.path.join(SCRIPT_DIR, PACKAGE_PARENT)))\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from deepeeg.helpers import CrossValidator\n",
        "from deepeeg.models import BaselineDeepEEG, DilatedDeepEEG, WindowedDeepEEG\n",
        "from deepeeg.dataset import DataLoader, Splitter, FixedLenGenerator\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "tensorflow version:  1.15.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gwzjFnB5ptIL",
        "colab_type": "code",
        "outputId": "f92a57d1-1f3e-49df-f2ad-1e3dc588d28d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "#@title # Set data path {display-mode: \"form\"}\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown Type in the folder in your google drive that contains numpy _data_ folder:\n",
        "\n",
        "parent_dir = 'soroush_deep_eeg'#@param {type:\"string\"}\n",
        "gdrive_path =  os.path.abspath(os.path.join('gdrive/My Drive', parent_dir))\n",
        "data_dir = os.path.join(gdrive_path, 'data')\n",
        "cv_results_dir = os.path.join(gdrive_path, 'cross_validation')\n",
        "if not os.path.exists(cv_results_dir):\n",
        "    os.mkdir(cv_results_dir)\n",
        "\n",
        "print('Data directory: ', data_dir)\n",
        "print('Cross validation results dir: ', cv_results_dir)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data directory:  /content/gdrive/My Drive/soroush_deep_eeg/data\n",
            "Cross validation results dir:  /content/gdrive/My Drive/soroush_deep_eeg/cross_validation\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_NdDuoHWpwe4",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title # Set Parameters\n",
        "\n",
        "batch_size = 80\n",
        "epochs = 100\n",
        "k = 10\n",
        "t = 10\n",
        "instance_duration = 4 \n",
        "instance_overlap = 1 \n",
        "sampling_rate = 256 \n",
        "n_channels = 19 \n",
        "task = 'rnr'\n",
        "data_mode = 'cross_subject'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QA43AGAEiKH8",
        "colab_type": "text"
      },
      "source": [
        "# 10times 10folds CV"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2aqgfC5aqCkP",
        "colab_type": "code",
        "cellView": "form",
        "outputId": "1e26b011-6a63-4ab2-a521-b410289ceb49",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 457
        }
      },
      "source": [
        "#@title ## BaselineDeepEEG\n",
        "\n",
        "model_name = 'BaselineDeepEEG'\n",
        "\n",
        "train_generator = FixedLenGenerator(batch_size=batch_size,\n",
        "                                    duration=instance_duration,\n",
        "                                    overlap=instance_overlap,\n",
        "                                    sampling_rate=sampling_rate,\n",
        "                                    is_train=True)\n",
        "\n",
        "test_generator = FixedLenGenerator(batch_size=8,\n",
        "                                   duration=instance_duration,\n",
        "                                   overlap=instance_overlap,\n",
        "                                   sampling_rate=sampling_rate,\n",
        "                                   is_train=False)\n",
        "\n",
        "params = {'task': task,\n",
        "          'data_mode': data_mode,\n",
        "          'main_res_dir': cv_results_dir,\n",
        "          'model_name': model_name,\n",
        "          'epochs': epochs,\n",
        "          'train_generator': train_generator,\n",
        "          'test_generator': test_generator,\n",
        "          't': t,\n",
        "          'k': k,\n",
        "          'channel_drop': True}\n",
        "\n",
        "validator = CrossValidator(**params)\n",
        "\n",
        "dataloader = DataLoader(data_dir,\n",
        "                        task,\n",
        "                        data_mode,\n",
        "                        sampling_rate,\n",
        "                        instance_duration,\n",
        "                        instance_overlap)\n",
        "data, labels = dataloader.load_data()\n",
        "\n",
        "input_shape = (sampling_rate * instance_duration,\n",
        "               n_channels)\n",
        "\n",
        "model_obj = BaselineDeepEEG(input_shape,\n",
        "                            model_name=model_name)\n",
        "\n",
        "scores = validator.do_cv(model_obj,\n",
        "                         data,\n",
        "                         labels)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/62 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Loading data ...\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 62/62 [00:47<00:00,  2.22it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train-test indices generated.\n",
            "time 1/10:\n",
            " step 1/10 ...\n",
            "   training instances:  5281\n",
            "   test instances:      638\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4074: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            " step 2/10 ...\n",
            "   training instances:  5244\n",
            "   test instances:      675\n",
            " step 3/10 ...\n",
            "   training instances:  5234\n",
            "   test instances:      685\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5WPcBNyWhoeY",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "source": [
        "#@title ## WindowedDeepEEG\n",
        "\n",
        "model_name = 'WindowedDeepEEG'\n",
        "\n",
        "train_generator = FixedLenGenerator(batch_size=batch_size,\n",
        "                                    duration=instance_duration,\n",
        "                                    overlap=instance_overlap,\n",
        "                                    sampling_rate=sampling_rate,\n",
        "                                    is_train=True)\n",
        "\n",
        "test_generator = FixedLenGenerator(batch_size=8,\n",
        "                                   duration=instance_duration,\n",
        "                                   overlap=instance_overlap,\n",
        "                                   sampling_rate=sampling_rate,\n",
        "                                   is_train=False)\n",
        "\n",
        "params = {'task': task,\n",
        "          'data_mode': data_mode,\n",
        "          'main_res_dir': cv_results_dir,\n",
        "          'model_name': model_name,\n",
        "          'epochs': epochs,\n",
        "          'train_generator': train_generator,\n",
        "          'test_generator': test_generator,\n",
        "          't': t,\n",
        "          'k': k,\n",
        "          'channel_drop': True}\n",
        "\n",
        "validator = CrossValidator(**params)\n",
        "\n",
        "dataloader = DataLoader(data_dir,\n",
        "                        task,\n",
        "                        data_mode,\n",
        "                        sampling_rate,\n",
        "                        instance_duration,\n",
        "                        instance_overlap)\n",
        "data, labels = dataloader.load_data()\n",
        "\n",
        "input_shape = (sampling_rate * instance_duration,\n",
        "               n_channels)\n",
        "\n",
        "model_obj = WindowedDeepEEG(input_shape,\n",
        "                            model_name=model_name)\n",
        "\n",
        "scores = validator.do_cv(model_obj,\n",
        "                         data,\n",
        "                         labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bOiA3QX5hudC",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "source": [
        "#@title ## DilatedDeepEEG\n",
        "\n",
        "model_name = 'DilatedDeepEEG'\n",
        "\n",
        "train_generator = FixedLenGenerator(batch_size=batch_size,\n",
        "                                    duration=instance_duration,\n",
        "                                    overlap=instance_overlap,\n",
        "                                    sampling_rate=sampling_rate,\n",
        "                                    is_train=True)\n",
        "\n",
        "test_generator = FixedLenGenerator(batch_size=8,\n",
        "                                   duration=instance_duration,\n",
        "                                   overlap=instance_overlap,\n",
        "                                   sampling_rate=sampling_rate,\n",
        "                                   is_train=False)\n",
        "\n",
        "params = {'task': task,\n",
        "          'data_mode': data_mode,\n",
        "          'main_res_dir': cv_results_dir,\n",
        "          'model_name': model_name,\n",
        "          'epochs': epochs,\n",
        "          'train_generator': train_generator,\n",
        "          'test_generator': test_generator,\n",
        "          't': t,\n",
        "          'k': k,\n",
        "          'channel_drop': True}\n",
        "\n",
        "validator = CrossValidator(**params)\n",
        "\n",
        "dataloader = DataLoader(data_dir,\n",
        "                        task,\n",
        "                        data_mode,\n",
        "                        sampling_rate,\n",
        "                        instance_duration,\n",
        "                        instance_overlap)\n",
        "data, labels = dataloader.load_data()\n",
        "\n",
        "input_shape = (sampling_rate * instance_duration,\n",
        "               n_channels)\n",
        "\n",
        "model_obj = DilatedDeepEEG(input_shape,\n",
        "                           model_name=model_name)\n",
        "\n",
        "scores = validator.do_cv(model_obj,\n",
        "                         data,\n",
        "                         labels)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}